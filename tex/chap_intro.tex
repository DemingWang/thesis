\chapter{引言}
\label{chap:introduction}
\section{概述}
随着互联网的发展、云计算和大数据等新兴技术的不断成熟，尤其是深度学习的发展，使得计算机视觉领域2D目标检测的准确率得到了空前的提高，但3D目标检测和位姿估计的研究还较少，其识别准确率还较低，实际运用还存在大量问题。

3D目标检测和位姿估计在工业自动化、军事侦查及医疗各个邻域有着大量需求，随着近几年高性价比RGB-D摄像头的出现，以及深度学习的浪潮，基于深度图像的3D目标检测的研究思路逐渐展现出优势。从Google的Project Tango到今年IPhone X的Face ID可以看到基于深度信息的三维识别和重建技术将会越来越流行。

本课题的主要研究目标是实现一套3D目标检测和位姿估计的视觉算法，能够识别出所需目标以及其在相机坐标系下的位姿。其理论意义在于区别与传统3D目标检测和位姿估计的方法，本文基于RGB-D图像通过将深度学习与传统视觉算法相结合，极大地提高了3D目标检测的准确率和位姿估计的精度，对工业自动化、医疗等领域有着巨大的实际应用价值。

\section{课题研究背景及现状分析}
3D目标检测和位姿估计的任务是识别出图像中有什么类型的物体，并给出物体在相机坐标系下的位姿，是对三维世界的感知理解。3D目标检测和位姿估计的结果可直接应用于实际机器人操作环境，但国内外3D目标检测和位姿估计的研究还相对较少。研究3D目标检测和位姿估计的问题一般可以分为一下几种研究思路：
\begin{itemize}
\item 基于模型(model-based)或几何(geometry-based)的方法；
\item 基于外观(appearance-based)或视图(view-based)的方法；
\item 基于局部特征匹配的方法； 
\item 基于深度图像的3D目标检测和位姿估计；
\end{itemize}

基于模型或几何的方法需要利用有关物体的先验知识，建立模型数据库，然后从输入图像数据中获取物体描述，并与模型库中描述进行匹配，该方法的优点是比较直观和易于理解，但缺点是算法运算量较大，而且在复杂环境下、物体遮挡、噪声干扰等情况下识别率往往很低。基于外观或视图的方法其实就是利用图像识别的方法来匹配目标，该方法对数据来源要求不高，在3D目标检测和位姿估计和图像检索系统中有广泛的应用，如Swain和Ballard等人提出一种全局特征匹配算法\cite{swain1991color}，用颜色直方图来表示一个物体，通过直方图的匹配来识别物体。基于局部特征匹配的方法提取局部图像块的特征用于匹配，该方法通过对视角改变局部准不变过程，来检测得到视图中三维物体的局部区域，然后通过从局部测量计算得到的不变量描述的区域集合来表示物体，该方法的关键在于局部图像区域的选择和基于这些区域的特征计算，具体有Lowe等人提出的尺度不变特征变换(SIFT)描述子\cite{lowe1999object}、Mikolajczyk和Schmid等人提出的Harris角点检测器和Hessian点检测器\cite{matas2004robust}、Chum等人提出的最稳定极值区域检测器\cite{chum2004enhancing}等，该方法的一个缺点就是不存在对于各种场景类型和图像变换类型都是最优的检测器，各种检测器之间存在互补性，结合各种检测器虽然能提高该方法的性能，但算法的计算量太大。基于深度图像的3D目标检测和位姿估计，是通过距离传感器如激光、红外等获取传感焦平面到目标表面的距离，深度图像仅依赖与物体的几何形状，不存在色彩图像阴影或表面投影等问题，因此利用深度图像进行三维物体的识别有一定的优势，并且由于近几年距离传感器越来越精确，基于深度图像的3D目标检测和位姿估计的研究逐渐多了起来。

随着近几年高性价比RGB-D摄像头的出现及计算机性能的提高，国外出现了基于RGB-D图像的3D目标检测和位姿估计的研究方法，RGB-D图像结合了物体形状、颜色以及深度信息，相比单个RGB图像或者单个深度图像有着无法比拟的优势，但相对地，信息的处理量和复杂度也相应地增加了，但深度学习的发展给这种研究方法带来了空前的机遇。Saurabh等人基于RGB-D图像提取了多种特征用于CNN网络的学习，加上SVM分类器大大提升了3D目标检测和位姿估计的准确率\cite{Gupta2014}；在此基础之上，Saurabh又引入了基于三维模型的方法，通过匹配已有的三维物体模型库，进一步提高了识别的准确率，并且识别速度也进一步增快了\cite{Gupta2013}；Alexandre等人将RGB-D四个通道分别输入卷积神经网络，并在各个通道之间使用转移学习的方法训练模型，该方法不经提高了3D目标检测和位姿估计的准确率，还减少了模型训练的时间\cite{alexandre20163d}；Rico和Clemens等人考虑具体机器人操作环境，从RGB-D图像中提取了六种特征，采用统计学习的方法，实现了多三维物体分类和识别\cite{jonschkowski2016probabilistic}，并在APC(Amazon Picking Challenge)上取得了冠军，可以说是将基于RGB-D图像和学习的方法具体应用到实际机器人操作环境中的典范，是目前3D目标检测和位姿估计领域内的顶尖水平。

随着互联网的发展、云计算和大数据等新兴技术的不断成熟，尤其是深度学习的引入，计算机视觉领域得到了空前的发展，对于二维图像中目标检测的准确率大大地提高了。但是二维目标识别给出的结果是框住可能目标的矩形框，其中部分像素并不是目标本身，而且缺少目标的姿态、尺寸等信息，所以其结果往往难以应用于实际机器人操作环境中。实际机器人操作环境需要目标准确的位置、姿态以及尺寸等信息，机器人才能采取合适的操作。因此，三维物体的识别对于实际机器人操作具有十分重要的意义和价值。相对于二维图像中目标的检测与识别，3D目标检测和位姿估计的相关研究，尤其是基于RGB-D图像的研究还相当少，因此对3D目标检测和位姿估计的研究十分有必要。基于RGB-D图像的3D目标检测和位姿估计的研究，引入机器学习中相关的学习方法如深度学习、支持向量机以及统计学习方法等，对3D目标检测和位姿估计的准确率提升、促进该问题的进一步解决有着巨大的帮助和十分重要的现实意义，有助于推动机器视觉的发展。

综上，3D目标检测和位姿估计的研究对机器人具体应用有着十分重要的意义，是机器人乃至整个人工智能领域发展的重要组成部分，然而国内外对3D目标检测和位姿估计的研究还相对较少，尤其是基于RGB-D图像和机器学习算法的3D目标检测和位姿估计的研究。机器学习算法，尤其是深度学习的引入对3D目标检测和位姿估计的准确率的提高有着不可估计的进步空间，因此，本文基于RGB-D图像和机器学习算法的3D目标检测和位姿估计的研究十分有必要，对机器视觉领域有着十分重要的价值，对于推动该领域的进一步发展具有重大意义

\section{研究内容与论文结构}
本文研究的内容是基于RGB-D图像的三维物体的识别，通过输入的RGB-D图像，给出物体的种类以及在相机坐标系下的位姿。旨在提出一种能实际应用到机器人的3D目标检测和位姿估计算法，基于深度学习技术和传统视觉算法以解决机器人的三维感知问题。本文的结构安排入下：

第一章即为本章，介绍3D视觉目标检测和位姿估计的研究意义、现状调研与本文的研究对象和主要内容框架。

第二章主要介绍了深度信息获取的现状以及所采用的RGB-D相机，并针对现有RGB-D相机存在的问题，提出了对偶RGB-
D相机结构。

第三章在Faster R-CNN和Mask R-CNN的基础上，通过引入HHA和Spatial Transformer Network，提出了3D Faster R-CNN和3D Mask R-CNN算法，用于解决纹理缺少物体的检测。

第四章介绍了基于4PCS算法和ICP算法提出的A4PCS-ICP算法，A4PCS-ICP算法通过结合4PCS和ICP算法提高了点云匹配的精度。

第五章在第二章和第三章的基础上，通过将3D Faster/Mask R-CNN和A4PCS-ICP算法结合，提出了3D-MRAI算法，该算法可以在输入RGB-D图中检测出物体的种类和位姿。

第六章介绍了所提出的三维物体目标检测和位姿估计算法3D-MRAI的具体应用——Bin-Picking，并通过实验评价了所设计的随机分拣视觉系统的性能。

第七章为本文的总结与进一步展望。

%%% Local Variables:
%%% TeX-master: "../thesis.tex"
%%% End: