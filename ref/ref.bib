% Encoding: UTF-8
@Book{tex,
	author    = "Donald E. Knuth",
	title     = "The {\TeX} Book",
	publisher = "Addison-Wesley Publishing Company",
	address   = "Reading, MA",
	year      = 1989,
	edition   = "15th",
}

@article{Heikkila2000,
abstract = {Modern CCD cameras are usually capable of a spatial accuracy greater$\backslash$nthan 1/50 of the pixel size. However, such accuracy is not easily$\backslash$nattained due to various error sources that can affect the image$\backslash$nformation process. Current calibration methods typically assume$\backslash$nthat the observations are unbiased, the only error is the zero-mean$\backslash$nindependent and identically distributed random noise in the observed$\backslash$nimage coordinates, and the camera model completely explains the$\backslash$nmapping between the 3-D coordinates and the image coordinates. In$\backslash$ngeneral, these conditions are not met, causing the calibration results$\backslash$nto be less accurate than expected. In this paper, a calibration$\backslash$nprocedure for precise 3-D computer vision applications is described.$\backslash$nIt introduces bias correction for circular control points and a$\backslash$nnon-recursive method for reversing the distortion model. The accuracy$\backslash$nanalysis is presented and the error sources that can reduce the$\backslash$ntheoretical accuracy are discussed. The tests with synthetic images$\backslash$nindicate improvements in the calibration results in limited error$\backslash$nconditions. In real images, the suppression of external error sources$\backslash$nbecomes a prerequisite for successful calibration.},
author = {Heikkil{\"{a}}, Janne},
doi = {10.1109/34.879788},
file = {:home/yongqi/papers/Geometric Camera Calibration.pdf:pdf},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
mendeley-groups = {bin-picking},
number = {10},
pages = {1066--1077},
pmid = {695},
title = {{Geometric camera calibration using circular control points}},
volume = {22},
year = {2000}
}

@article{Staranowicz2014,
author = {Staranowicz, Aaron and Brown, Garrett R and Morbidi, Fabio and Mariottini, Gian-luca},
file = {:home/yongqi/papers/6bc1e45c39cbb603ea288200e9d560476178.pdf:pdf},
keywords = {camera calibration,com-,kinect,rgb-depth cameras},
mendeley-groups = {bin-picking},
pages = {265--278},
title = {{Easy-to-Use and Accurate Calibration of RGB-D Cameras from Spheres}},
year = {2014}
}

@article{Brown1966,
author="BROWN, D. C.",
title="Decentering Distortion of Lenses",
journal="Photogrammetric Engineering and Remote Sensing",
ISSN="",
publisher="",
year="1966",
month="",
volume="",
number="",
pages="",
URL="https://ci.nii.ac.jp/naid/10022411406/en/",
DOI="",
}

@article{Zhang2002,
abstract = {We propose a flexible new technique to easily calibrate a camera. It is well suited for use without specialized knowledge of 3D geometry or computer vision. The technique only requires the camera to observe a planar pattern shown at a few (at least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique, and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthog- onal planes, the proposed technique is easy to use and flexible. It advances 3D computer vision one step from laboratory environments to real world use.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Zhang, Zhengyou},
doi = {10.1109/34.888718},
eprint = {arXiv:1011.1669v3},
file = {:home/yongqi/papers/00888718.pdf:pdf},
isbn = {MSR-TR-98-71},
issn = {01628828},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
mendeley-groups = {bin-picking},
number = {11},
pages = {1330--1334},
pmid = {131},
title = {{A Flexible New Technique for Camera Calibration (Technical Report)}},
volume = {22},
year = {2002}
}

@article{Geiger2010,
author = {Geiger, Andreas and Roser, Martin and Urtasun, Raquel},
file = {:home/yongqi/papers/geiger{\_}et{\_}al{\_}accv10.pdf:pdf},
journal = {Accv},
mendeley-groups = {bin-picking},
title = {{Efficient Large-Scale Stereo Matching}},
year = {2010}
}

@inproceedings{Sur2008,
abstract = {Fundamental matrix estimation is difficult since it is often based$\backslash$non correspondences that are spoilt by noise and outliers. Outliers$\backslash$nmust be thrown out via robust statistics, and noise gives uncertainty.$\backslash$nIn this article we provide a closed-form formula for the uncertainty$\backslash$nof the so-called 8 point algorithm, which is a basic tool for fundamental$\backslash$nmatrix estimation via robust methods. As an application, we modify$\backslash$na well established robust algorithm accordingly, leading to a new$\backslash$ncriterion to recover point correspondences under epipolar constraint,$\backslash$nbalanced by the uncertainty of the estimation.},
author = {Sur, F. and Noury, N. and Berger, M.-O.},
booktitle = {Procedings of the British Machine Vision Conference 2008},
doi = {10.5244/C.22.96},
isbn = {1-901725-36-7},
pages = {96.1--96.10},
title = {{Computing the Uncertainty of the 8 point Algorithm for Fundamental Matrix Estimation}},
url = {http://www.bmva.org/bmvc/2008/papers/269.html},
year = {2008}
}

@article{Loop2001,
abstract = {Image rectification is the process of applying a pair of 2D$\backslash$nprojective transforms, or homographies, to a pair of images whose$\backslash$nepipolar geometry is known so that epipolar lines in the original images$\backslash$nmap to horizontally aligned lines in the transformed images. We propose$\backslash$na novel technique for image rectification based on geometrically well$\backslash$ndefined criteria such that image distortion due to rectification is$\backslash$nminimized. This is achieved by decomposing each homography into a$\backslash$nspecialized projective transform, a similarity transform, followed by a$\backslash$nshearing transform. The effect of image distortion at each stage is$\backslash$ncarefully considered},
author = {Loop, C. and {Zhengyou Zhang}},
doi = {10.1109/CVPR.1999.786928},
file = {:home/yongqi/papers/b400458474493f8bbe547d7a02e8b0956795.pdf:pdf},
isbn = {0-7695-0149-4},
issn = {1063-6919},
journal = {Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149)},
mendeley-groups = {bin-picking},
pages = {125--131},
pmid = {786928},
title = {{Computing rectifying homographies for stereo vision}},
url = {http://ieeexplore.ieee.org/document/786928/},
volume = {1},
year = {2001}
}
@article{Ren,
archivePrefix = {arXiv},
arxivId = {arXiv:1506.01497v3},
author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
eprint = {arXiv:1506.01497v3},
file = {:home/yongqi/papers/Ren et al. - Unknown - Faster R-CNN Towards Real-Time Object Detection with Region Proposal Networks.pdf:pdf},
mendeley-groups = {DeepLearning},
pages = {1--14},
title = {{Faster R-CNN : Towards Real-Time Object Detection with Region Proposal Networks}}
}
@article{He2017,
abstract = {We present a conceptually simple, flexible, and general framework for object instance segmentation. Our approach efficiently detects objects in an image while simultaneously generating a high-quality segmentation mask for each instance. The method, called Mask R-CNN, extends Faster R-CNN by adding a branch for predicting an object mask in parallel with the existing branch for bounding box recognition. Mask R-CNN is simple to train and adds only a small overhead to Faster R-CNN, running at 5 fps. Moreover, Mask R-CNN is easy to generalize to other tasks, e.g., allowing us to estimate human poses in the same framework. We show top results in all three tracks of the COCO suite of challenges, including instance segmentation, bounding-box object detection, and person keypoint detection. Without tricks, Mask R-CNN outperforms all existing, single-model entries on every task, including the COCO 2016 challenge winners. We hope our simple and effective approach will serve as a solid baseline and help ease future research in instance-level recognition. Code will be made available.},
archivePrefix = {arXiv},
arxivId = {1703.06870},
author = {He, Kaiming and Gkioxari, Georgia and Doll{\'{a}}r, Piotr and Girshick, Ross},
eprint = {1703.06870},
file = {:home/yongqi/papers/He et al. - 2017 - Mask R-CNN.pdf:pdf},
mendeley-groups = {DeepLearning},
title = {{Mask R-CNN}},
url = {http://arxiv.org/abs/1703.06870},
year = {2017}
}
